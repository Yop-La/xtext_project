
import pandas as pd
mml_data = pd.read_csv("/home/ensai/Dropbox/ENSAI/Ressources/S5/dsl/projet/ensai-sid-mml/org.xtext.example.mml/mml_data/iris.csv", sep=",")
target_index = "-1"

if target_index.replace('-','').isdigit():
    target_index = int(target_index)
else:
    target_index = list(mml_data.columns).index(target_index)

target = mml_data.iloc[:,target_index]
predictors = mml_data.drop(mml_data.columns[target_index], axis=1)

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification



def train_model(X_train, y_train, n_estimators=100, max_depth=2,random_state=0):
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,random_state=random_state)
    model.fit(X_train, y_train)
    return(model)
    
def test_model(model, X_test):
    predictions = model.predict(X_test)
    return(list(predictions))
    

metrics = "RECALL+PRECISION";
metrics = metrics.split("+")

from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score

def compute_metrics(y_prediction,y_test,metrics):
    
    metrics_performance = {};
    
    for metric in metrics:

        
        if "RECALL" == metric:        
            recall = recall_score(y_test, y_prediction, average='macro')     
            metrics_performance["RECALL"] = recall


        if "PRECISION" == metric:
            precision = precision_score(y_test, y_prediction, average='macro')     
            metrics_performance["PRECISION"] = precision

        if "F1" == metric:
            f1 = f1_score(y_test, y_prediction, average='macro')     
            metrics_performance["F1"] = f1

    return(metrics_performance)
from sklearn.model_selection import KFold

n_splits = 20

kf = KFold(n_splits=n_splits)
kf.get_n_splits(predictors)


list_of_dataframes = []

index = 0
for train_index, test_index in kf.split(predictors):
   
    X_train, X_test = predictors.iloc[train_index,:], predictors.iloc[test_index,:]
    y_train, y_test = target.iloc[train_index], target.iloc[test_index]
   
    model = train_model(X_train, y_train)
   
    y_prediction = test_model(model, X_test)
   
    res_metrics = compute_metrics(y_prediction,y_test,metrics)
   
    res_metrics_tempo = pd.DataFrame(res_metrics, index=[index])
    index=index+1
    
    list_of_dataframes.append(res_metrics_tempo)
    
    
metrics = pd.concat(list_of_dataframes)
metrics = dict(metrics.mean())

path_metrics_python = "/home/ensai/Dropbox/ENSAI/Ressources/S5/dsl/projet/ensai-sid-mml/org.xtext.example.mml/mml_data/metrics_SCIKIT"

import json
json_metrics = json.dumps(metrics, ensure_ascii=False)

with open(path_metrics_python, "w") as text_file:
    text_file.write(json_metrics)
    
print(json_metrics)
